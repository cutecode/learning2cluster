TODO:
- Maybe print the network summary to somewhere?
- The validation loss seems to be always worse than the training loss, but the used data is always generated?
  - Test what happens if the training data is used for the validation run. See: BUG_LOSS.txt
- Git-Repo erstellen
- Use weithed loss-values for the similarities output
    - Calculate the expected 1s and 0s and weight them
    - See: https://github.com/fchollet/keras/issues/2115
           https://github.com/fchollet/keras/issues/3068
           https://datascience.stackexchange.com/questions/13490/how-to-set-class-weights-for-imbalanced-classes-in-keras
           https://github.com/fchollet/keras/issues/4735
    - See: https://stackoverflow.com/questions/46009619/keras-weighted-binary-crossentropy
        - Maybe use the log / sqrt of the weights?
        - Implement log / sqrt / f(x) normalize => use the current weights and appliy w_0n = f(w_0), and sum(f(w_i)) = count of weights
    - Test the current implementation somehow
        - Create a minimal network and do some tests: A network without weights and a defined and fixed input, check
          if the loss is exactly equal to the manually computed value. Another test is to directly check the output
          of the weighted and unweighted binary crossentropys
    - For the weighted cross entropy: The total weight sum should be the number of all summands and not 1 like now. (obviously)
    - For debugging: Print the actual percentage of zeros and ones in the y values
- Bei Graphen eine Art Average-Kurve durchziehen
- DataProvider aufräumen: Man soll einen Range doer eine fixe ANzahl CLuster mitgeben. Aktuell ist das ein wenig Bastel
- Use the wrapper "concat_layer" for concatenations. Why? The "Concatenate" layer cannot handle single inputs
- Cluster counts things are bugg (see fixedc, and see scr 4)
- fixedc contains a Bug (see BUG_FIXEC): A bug while generating data. This has to be fixed
- Im Konstruktor bei "super" jeweils als ersten Parameter die aktuelle Klasse mitgeben und nicht die Superklasse
- Optimizer state wird nicht richtig gespeichert / geladen, siehe: https://groups.google.com/forum/#!topic/keras-users/cNvLLrarfN4
- Implement debug-Outputs: Just print them in some nice format (e.g. use a Prefix DEBUG_ or something like this, or add
  a bool "debug" to the _s_layer method)
  - Edit: While building the network one may add layers to an additional array "debug_output"
- Falls kein Cluster COunt beim Output ist, sind ide Graphen verkehrt (siehe try00_fixedc Graph)

IDEAS:
- Try00 nehmen mit mehr LSTM-Layer und mehr Dense-Units
- Try00 mit wsich wiederholenden LSTM-Layern
- Try00 mit nur einer möglichen Cluster-Anzahl testen
  - Der DataProvider darf nun auf keinen Fall mehr zu wenige Cluster liefern
- Try00 in der Ausgabe mit nur einer Cluster-Anzahl testen, effektiv können aber beliebig viel Cluster in der Eingabe sein, aber
  weniger oder gleich viele wie im neuronalen Netz möglich sind. Die effektive Anzahl Cluster wird festgelegt durch die
  nicht leeren Cluster in der Ausgabe

NICE2HAVE:
- Email-Notify einbauen

DONE:
- Save optimizer config (to_config(), from_config())
  - save/load optimizer state
- Implement save/load network model
  - Abstract in BaseNN, impl in subclasses
- Implement save/load training history
  - This could be included in the general save load method (add a flag "include_history" or something like this)
- Implement something to always store the best model etc.
  - Maybe implement events or something like this
- Implement validation
  - Use test data for this
- Implement some nice plots (at least validation / training loss)
- Validate only every nth iteration
- Create a nice output while training (something like lasagne / nolearn) -> the current output sucks
  - Use the own history object to generate a nice output
- Always print best iteration
- Cluster Count Distribution wird nicht richtig geplottet
- Print and store the required time for each iteration
- Always print loss plots
- Iteration print: Only print non-NaN values
- Saving files:
  - First create a temporary file
  - After writing it, move it to the target location
  - Why? Because if someone stops the program it is very uncool to have broken weights etc.
- Print total training time
- The prediction pictures are wrong
- Create colorized output during the training
  - Also: Order the output by training, then validation
  - There is an empty line between the time and the training line
  - Highlight the iteration number (and the best loss)
  - If a loss is the best loss, print is green
  - For the iteration output: Also print the best training loss
- Print the amount of network parameters
- Prediction graphics for all cluster counts: Add the probability to the title
